# ğŸ—ï¸ VK CHART AI â€” ĞŸĞĞ›ĞĞĞ¯ ĞĞ Ğ¥Ğ˜Ğ¢Ğ•ĞšĞ¢Ğ£Ğ Ğ Ğ¡Ğ˜Ğ¡Ğ¢Ğ•ĞœĞ«

**Ğ’ĞµÑ€ÑĞ¸Ñ**: 2.0  
**Ğ”Ğ°Ñ‚Ğ°**: 2024-12-02  
**ĞĞ²Ñ‚Ğ¾Ñ€**: Claude + Vitaly  
**Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ**: In Progress
**ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ v2.0**: Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Lang* Stack (LangGraph, LangSmith, LangServe)

---

## ğŸ“‹ ĞĞ“Ğ›ĞĞ’Ğ›Ğ•ĞĞ˜Ğ•

1. [Executive Summary](#1-executive-summary)
2. [High-Level Architecture](#2-high-level-architecture)
3. [ĞšĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹](#3-ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹-ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹)
4. [Data Flow](#4-data-flow)
5. [API Contracts](#5-api-contracts)
6. [Database Schema](#6-database-schema)
7. [AI Agents Design](#7-ai-agents-design)
8. [Knowledge Base Structure](#8-knowledge-base-structure)
9. [Normalization System](#9-normalization-system)
10. [Learning Mechanism](#10-learning-mechanism)
11. [Technology Stack](#11-technology-stack)
12. [Implementation Phases](#12-implementation-phases)
13. [Risks & Mitigations](#13-risks--mitigations)
14. [LangGraph & LangSmith Integration](#14-langgraph--langsmith-integration)

---

## 1. EXECUTIVE SUMMARY

### ğŸ¯ Ğ¦ĞµĞ»ÑŒ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹
ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ vessel-cargo matching Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¾Ñ„Ñ„ĞµÑ€Ğ¾Ğ² Ğ´Ğ»Ñ Ğ¼Ğ¾Ñ€ÑĞºĞ¸Ñ… Ñ„Ñ€Ğ°Ñ…Ñ‚Ğ¾Ğ²Ñ‹Ñ… Ğ±Ñ€Ğ¾ĞºĞµÑ€Ğ¾Ğ².

### ğŸ”‘ ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ

| ĞÑĞ¿ĞµĞºÑ‚ | Ğ ĞµÑˆĞµĞ½Ğ¸Ğµ | ĞĞ±Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ |
|--------|---------|-------------|
| **ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°** | Laravel + Python microservice | Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰ÑƒÑ Ğ¸Ğ½Ñ„Ñ€Ğ°ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ |
| **ĞÑ‡ĞµÑ€ĞµĞ´Ğ¸** | RabbitMQ | Ğ£Ğ¶Ğµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ Ğ² Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğµ |
| **AI Agents** | 2 Ğ°Ğ³ĞµĞ½Ñ‚Ğ° (Scoring + Message) | Ğ Ğ°Ğ·Ğ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸ |
| **LLM** | Claude API (primary) | Ğ›ÑƒÑ‡ÑˆĞ¸Ğ¹ Ğ´Ğ»Ñ reasoning Ğ¸ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ² |
| **Vector Search** | MongoDB Atlas | Ğ£Ğ¶Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½ |
| **Knowledge** | Hybrid (Rules + RAG) | Ğ‘Ğ°Ğ»Ğ°Ğ½Ñ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ğ³Ğ¸Ğ±ĞºĞ¾ÑÑ‚Ğ¸ |
| **â˜… State Management** | **LangGraph** | **Workflow orchestration, conditional routing** |
| **â˜… Observability** | **LangSmith** | **Tracing, evaluation, monitoring** |
| **â˜… API Deployment** | **LangServe** | **FastAPI streaming endpoints** |

### ğŸ“Š ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸ ÑƒÑĞ¿ĞµÑ…Ğ°
- Ğ¢Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ ÑĞºĞ¾Ñ€Ğ¸Ğ½Ğ³Ğ°: >85% ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğµ Ñ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ½Ğ¾Ğ¹ Ğ¾Ñ†ĞµĞ½ĞºĞ¾Ğ¹
- Ğ’Ñ€ĞµĞ¼Ñ ÑĞºĞ¾Ñ€Ğ¸Ğ½Ğ³Ğ°: <5 ÑĞµĞº Ğ½Ğ° Ğ¾Ğ´Ğ½Ğ¾ ÑÑƒĞ´Ğ½Ğ¾
- ĞšĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²: >90% Ğ¾Ğ´Ğ¾Ğ±Ñ€ĞµĞ½Ğ¸Ğµ Ğ±ĞµĞ· Ğ¿Ñ€Ğ°Ğ²Ğ¾Ğº

---

## 2. HIGH-LEVEL ARCHITECTURE

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              VK CHARTS SYSTEM                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                        LARAVEL APPLICATION                            â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚   Vessels   â”‚  â”‚   Cargos    â”‚  â”‚  Companies  â”‚  â”‚    UI/API   â”‚  â”‚   â”‚
â”‚  â”‚  â”‚   Module    â”‚  â”‚   Module    â”‚  â”‚   Module    â”‚  â”‚   Gateway   â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚         â”‚                â”‚                â”‚                â”‚         â”‚   â”‚
â”‚  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚   â”‚
â”‚  â”‚                                   â”‚                                   â”‚   â”‚
â”‚  â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚   â”‚
â”‚  â”‚                    â”‚     EVENT DISPATCHER        â”‚                   â”‚   â”‚
â”‚  â”‚                    â”‚  (Cargo/Vessel/Comment)     â”‚                   â”‚   â”‚
â”‚  â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                      â”‚                                       â”‚
â”‚                                      â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                          RABBITMQ                                      â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚  â”‚  scoring    â”‚  â”‚  messages   â”‚  â”‚  learning   â”‚  â”‚  normalize  â”‚   â”‚  â”‚
â”‚  â”‚  â”‚   queue     â”‚  â”‚   queue     â”‚  â”‚   queue     â”‚  â”‚   queue     â”‚   â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚            â”‚                â”‚                â”‚                â”‚             â”‚
â”‚            â–¼                â–¼                â–¼                â–¼             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                     PYTHON AI SERVICE (FastAPI)                       â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚   â”‚
â”‚  â”‚  â”‚  SCORING AGENT  â”‚  â”‚  MESSAGE AGENT  â”‚  â”‚ NORMALIZER      â”‚       â”‚   â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚       â”‚   â”‚
â”‚  â”‚  â”‚  â”‚ P1-P7     â”‚  â”‚  â”‚  â”‚ Email     â”‚  â”‚  â”‚ â”‚ Rules     â”‚   â”‚       â”‚   â”‚
â”‚  â”‚  â”‚  â”‚ Criteria  â”‚  â”‚  â”‚  â”‚ Templates â”‚  â”‚  â”‚ â”‚ Engine    â”‚   â”‚       â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚       â”‚   â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚       â”‚   â”‚
â”‚  â”‚  â”‚  â”‚ Tools     â”‚  â”‚  â”‚  â”‚ Personal- â”‚  â”‚  â”‚ â”‚ LLM       â”‚   â”‚       â”‚   â”‚
â”‚  â”‚  â”‚  â”‚ (intake,  â”‚  â”‚  â”‚  â”‚ ization   â”‚  â”‚  â”‚ â”‚ Fallback  â”‚   â”‚       â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  distance)â”‚  â”‚  â”‚  â”‚ Engine    â”‚  â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚       â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚       â”‚   â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚ â”‚ Auto-Add  â”‚   â”‚       â”‚   â”‚
â”‚  â”‚  â”‚  â”‚ RAG       â”‚  â”‚  â”‚  â”‚ LangChain â”‚  â”‚  â”‚ â”‚ Aliases   â”‚   â”‚       â”‚   â”‚
â”‚  â”‚  â”‚  â”‚ Retriever â”‚  â”‚  â”‚  â”‚ Chain     â”‚  â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚       â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
â”‚  â”‚  â”‚                    LEARNING MODULE                               â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  â”‚ Correctionâ”‚  â”‚ Pattern   â”‚  â”‚ Feedback  â”‚  â”‚ Weight    â”‚    â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  â”‚ Collector â”‚  â”‚ Extractor â”‚  â”‚ Analyzer  â”‚  â”‚ Adjuster  â”‚    â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                      â”‚                                       â”‚
â”‚                                      â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                        MONGODB ATLAS                                   â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚  â”‚  scoring_   â”‚  â”‚  knowledge_ â”‚  â”‚  learning_  â”‚  â”‚  aliases_   â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  results    â”‚  â”‚  embeddings â”‚  â”‚  patterns   â”‚  â”‚  auto       â”‚   â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚  â”‚
â”‚  â”‚  â”‚  message_   â”‚  â”‚  distances_ â”‚  â”‚  normalize_ â”‚                    â”‚  â”‚
â”‚  â”‚  â”‚  history    â”‚  â”‚  cache      â”‚  â”‚  logs       â”‚                    â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                         EXTERNAL SERVICES                              â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚  â”‚
â”‚  â”‚  â”‚  Claude API â”‚  â”‚  OpenAI API â”‚  â”‚  Gmail API  â”‚                    â”‚  â”‚
â”‚  â”‚  â”‚  (Primary)  â”‚  â”‚  (Backup)   â”‚  â”‚  (Send)     â”‚                    â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. ĞšĞĞœĞŸĞĞĞ•ĞĞ¢Ğ« Ğ¡Ğ˜Ğ¡Ğ¢Ğ•ĞœĞ«

### 3.1 Laravel Application (Existing)

**Ğ Ğ¾Ğ»ÑŒ**: ĞÑ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ‚Ğ¾Ñ€, UI, Data Gateway

**ĞĞ¾Ğ²Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹ Ğ´Ğ»Ñ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ**:

```php
// app/Events/
CargoUpdatedEvent.php          // Ğ¢Ñ€Ğ¸Ğ³Ğ³ĞµÑ€ Ğ¿Ñ€Ğ¸ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¸ Ğ³Ñ€ÑƒĞ·Ğ°
VesselPositionChangedEvent.php // Ğ¢Ñ€Ğ¸Ğ³Ğ³ĞµÑ€ Ğ¿Ñ€Ğ¸ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¸ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸
CommentsUpdatedEvent.php       // Ğ¢Ñ€Ğ¸Ğ³Ğ³ĞµÑ€ Ğ¿Ñ€Ğ¸ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¸ ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²
ScoringRequestedEvent.php      // Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ Ğ½Ğ° ÑĞºĞ¾Ñ€Ğ¸Ğ½Ğ³

// app/Jobs/
RequestScoringJob.php          // ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ğ² RabbitMQ
ProcessScoringResultJob.php    // ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²
RequestMessageGenerationJob.php // Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²

// app/Services/
AIServiceClient.php            // HTTP ĞºĞ»Ğ¸ĞµĞ½Ñ‚ Ğº Python
ScoringResultProcessor.php     // ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²
TriggerManager.php             // Ğ£Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ñ‚Ñ€Ğ¸Ğ³Ğ³ĞµÑ€Ğ°Ğ¼Ğ¸

// app/Models/
ScoringResult.php              // Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ ÑĞºĞ¾Ñ€Ğ¸Ğ½Ğ³Ğ°
LearningFeedback.php           // ĞĞ±Ñ€Ğ°Ñ‚Ğ½Ğ°Ñ ÑĞ²ÑĞ·ÑŒ
NormalizationLog.php           // Ğ›Ğ¾Ğ³Ğ¸ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸
```

### 3.2 Python AI Service

**Ğ Ğ¾Ğ»ÑŒ**: AI-Ğ»Ğ¾Ğ³Ğ¸ĞºĞ°, ÑĞºĞ¾Ñ€Ğ¸Ğ½Ğ³, Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²

**Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°**:

```
vkchart-ai-service/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                    # FastAPI entry point
â”‚   â”œâ”€â”€ config.py                  # Configuration
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ scoring_agent.py       # Scoring Agent
â”‚   â”‚   â”œâ”€â”€ message_agent.py       # Message Agent
â”‚   â”‚   â””â”€â”€ base_agent.py          # Base class
â”‚   â”‚
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ intake_calculator.py   # P5 Intake calculation
â”‚   â”‚   â”œâ”€â”€ distance_calculator.py # Distance estimation
â”‚   â”‚   â”œâ”€â”€ port_restrictions.py   # Port data lookup
â”‚   â”‚   â”œâ”€â”€ comments_parser.py     # Comments extraction
â”‚   â”‚   â””â”€â”€ eta_calculator.py      # ETA/Readiness calc
â”‚   â”‚
â”‚   â”œâ”€â”€ normalizers/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ port_normalizer.py     # Port normalization
â”‚   â”‚   â”œâ”€â”€ region_normalizer.py   # Region normalization
â”‚   â”‚   â”œâ”€â”€ cargo_normalizer.py    # Cargo type normalization
â”‚   â”‚   â”œâ”€â”€ rules_engine.py        # Fast rules-based
â”‚   â”‚   â””â”€â”€ llm_fallback.py        # LLM fallback
â”‚   â”‚
â”‚   â”œâ”€â”€ knowledge/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ rag_retriever.py       # RAG implementation
â”‚   â”‚   â”œâ”€â”€ embeddings.py          # Embedding generation
â”‚   â”‚   â””â”€â”€ knowledge_loader.py    # Load YAML/TXT files
â”‚   â”‚
â”‚   â”œâ”€â”€ learning/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ feedback_collector.py  # Collect corrections
â”‚   â”‚   â”œâ”€â”€ pattern_extractor.py   # Extract patterns
â”‚   â”‚   â””â”€â”€ weight_adjuster.py     # Adjust scoring weights
â”‚   â”‚
â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ scoring.py             # Scoring request/response
â”‚   â”‚   â”œâ”€â”€ message.py             # Message request/response
â”‚   â”‚   â””â”€â”€ common.py              # Shared schemas
â”‚   â”‚
â”‚   â”œâ”€â”€ workers/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ scoring_worker.py      # RabbitMQ consumer
â”‚   â”‚   â”œâ”€â”€ message_worker.py      # RabbitMQ consumer
â”‚   â”‚   â””â”€â”€ learning_worker.py     # RabbitMQ consumer
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ llm_client.py          # LLM abstraction layer
â”‚       â”œâ”€â”€ mongo_client.py        # MongoDB connection
â”‚       â””â”€â”€ logger.py              # Logging
â”‚
â”œâ”€â”€ knowledge_base/
â”‚   â”œâ”€â”€ proximity_scoring_matrix.yaml
â”‚   â”œâ”€â”€ regional_trade_patterns.yaml
â”‚   â”œâ”€â”€ intake_calculator_formula.yaml
â”‚   â”œâ”€â”€ vessel_size_classification.yaml
â”‚   â”œâ”€â”€ port_restrictions_map.yaml
â”‚   â”œâ”€â”€ comments_processing_guide.yaml
â”‚   â”œâ”€â”€ open_area_comments_scoring.yaml
â”‚   â”œâ”€â”€ readiness_eta_scoring.yaml
â”‚   â””â”€â”€ email_templates/
â”‚       â”œâ”€â”€ case_a_strong_match.txt
â”‚       â”œâ”€â”€ case_b_not_ideal.txt
â”‚       â”œâ”€â”€ reminder_1.txt
â”‚       â””â”€â”€ whatsapp_templates.txt
â”‚
â”œâ”€â”€ aliases/
â”‚   â”œâ”€â”€ ports_aliases.yaml         # Port name aliases
â”‚   â”œâ”€â”€ regions_aliases.yaml       # Region aliases
â”‚   â”œâ”€â”€ cargo_aliases.yaml         # Cargo type aliases
â”‚   â””â”€â”€ auto_added/                # Auto-added by system
â”‚       â””â”€â”€ pending_review.yaml
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_scoring_agent.py
â”‚   â”œâ”€â”€ test_message_agent.py
â”‚   â”œâ”€â”€ test_normalizers.py
â”‚   â””â”€â”€ test_tools.py
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ docker-compose.yaml
```

### 3.3 RabbitMQ Queues

| Queue Name | Producer | Consumer | Purpose |
|------------|----------|----------|---------|
| `vkchart.scoring.requests` | Laravel | Python | Scoring requests |
| `vkchart.scoring.results` | Python | Laravel | Scoring results |
| `vkchart.messages.requests` | Laravel | Python | Message generation |
| `vkchart.messages.results` | Python | Laravel | Generated messages |
| `vkchart.learning.feedback` | Laravel | Python | User corrections |
| `vkchart.normalize.requests` | Laravel | Python | Normalization requests |
| `vkchart.normalize.logs` | Python | Laravel | Auto-added aliases |

### 3.4 MongoDB Collections

```javascript
// Database: vkchart_ai

// 1. Scoring Results (transactional)
db.scoring_results {
  _id: ObjectId,
  vessel_id: Number,
  cargo_id: Number,
  
  scores: {
    p1_proximity: { score: Number, max: 20, reasoning: String },
    p1a_patterns: { score: Number, max: 15, reasoning: String },
    p2_regional: { score: Number, max: 15, reasoning: String },
    p3_cargo: { score: Number, max: 15, reasoning: String },
    p4_last_ports: { score: Number, max: 10, reasoning: String },
    p5_intake: { score: Number, max: 15, reasoning: String },
    p6_open_area: { score: Number, range: [-50, 25], reasoning: String },
    p7_readiness: { score: Number, max: 10, reasoning: String }
  },
  
  final_score: Number,
  classification: String,  // "excellent" | "good" | "acceptable" | "marginal" | "poor"
  is_blocked: Boolean,
  block_reason: String,
  
  reasoning_summary: String,
  strengths: [String],
  weaknesses: [String],
  recommendation: String,
  
  snapshot: {
    vessel: Object,  // Frozen vessel data
    cargo: Object,   // Frozen cargo data
    company: Object  // Frozen company data
  },
  
  metadata: {
    model_used: String,
    processing_time_ms: Number,
    knowledge_files_used: [String],
    similar_patterns_found: Number
  },
  
  created_at: Date,
  updated_at: Date,
  version: Number
}

// 2. Knowledge Embeddings (for RAG)
db.knowledge_embeddings {
  _id: ObjectId,
  source_file: String,
  chunk_id: String,
  chunk_text: String,
  embedding: [Number],  // Vector 1536 dimensions
  metadata: {
    criterion: String,  // "P1" | "P2" | etc.
    category: String,   // "rule" | "example" | "pattern"
    keywords: [String]
  },
  created_at: Date
}

// Index for vector search
db.knowledge_embeddings.createIndex(
  { embedding: "vectorSearch" },
  { 
    name: "vector_index",
    vectorSearchOptions: {
      dimensions: 1536,
      similarity: "cosine"
    }
  }
)

// 3. Learning Patterns
db.learning_patterns {
  _id: ObjectId,
  pattern_type: String,  // "score_correction" | "text_edit" | "alias_add"
  
  context: {
    vessel_type: String,
    cargo_type: String,
    region_from: String,
    region_to: String,
    season: String
  },
  
  original: {
    score: Number,
    reasoning: String
  },
  
  corrected: {
    score: Number,
    reasoning: String,
    user_explanation: String
  },
  
  confidence: Number,  // How many times confirmed
  applied_count: Number,
  
  created_by: String,
  created_at: Date,
  last_applied: Date
}

// 4. Auto-Added Aliases (pending review)
db.aliases_auto {
  _id: ObjectId,
  entity_type: String,  // "port" | "region" | "cargo"
  
  original_value: String,
  normalized_value: String,
  
  source: String,  // "llm_fallback" | "fuzzy_match"
  confidence: Number,
  
  context: {
    vessel_id: Number,
    cargo_id: Number,
    field_name: String
  },
  
  status: String,  // "pending" | "approved" | "rejected"
  reviewed_by: String,
  reviewed_at: Date,
  rejection_reason: String,
  
  created_at: Date
}

// 5. Message History
db.message_history {
  _id: ObjectId,
  vessel_id: Number,
  cargo_id: Number,
  company_id: Number,
  person_id: Number,
  
  message_type: String,  // "offer" | "reminder_1" | "reminder_2" | "whatsapp"
  channel: String,  // "email" | "whatsapp" | "teams"
  
  generated_text: String,
  edited_text: String,
  was_edited: Boolean,
  
  scoring_result_id: ObjectId,
  
  personalization: {
    tone: String,
    language: String,
    highlights_used: [String]
  },
  
  sent_at: Date,
  response_received: Boolean,
  response_category: String,
  
  created_at: Date
}

// 6. Distances Cache
db.distances_cache {
  _id: ObjectId,
  port_from: String,  // UNLOCODE
  port_to: String,    // UNLOCODE
  distance_nm: Number,
  route_type: String,  // "direct" | "via_suez" | "via_gibraltar"
  source: String,      // "calculated" | "seadistances" | "manual"
  created_at: Date,
  expires_at: Date
}

// 7. Normalization Logs
db.normalization_logs {
  _id: ObjectId,
  entity_type: String,
  original_value: String,
  normalized_value: String,
  method: String,  // "exact_match" | "fuzzy" | "llm"
  confidence: Number,
  processing_time_ms: Number,
  created_at: Date
}
```

---

## 4. DATA FLOW

### 4.1 Scoring Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           SCORING DATA FLOW                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[1] TRIGGER
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    Event: CargoUpdated / VesselPositionChanged
â”‚   LARAVEL   â”‚    
â”‚  (Trigger)  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                     â”‚
     â”‚                                                              â”‚
     â”‚ [2] Prepare Snapshot                                         â”‚
     â–¼                                                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  SNAPSHOT DATA                                               â”‚    â”‚
â”‚  {                                                           â”‚    â”‚
â”‚    vessel: { id, name, dwt, flag, open_area, open_date,     â”‚    â”‚
â”‚              comments, position, destination, eta }          â”‚    â”‚
â”‚    cargo: { id, type, quantity, load_port, disch_port,      â”‚    â”‚
â”‚             laycan_start, laycan_end, rate }                 â”‚    â”‚
â”‚    company: { id, name, comments, preferences }              â”‚    â”‚
â”‚    person: { id, name, comments, comm_style }                â”‚    â”‚
â”‚  }                                                           â”‚    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
     â”‚                                                              â”‚
     â”‚ [3] Publish to Queue                                         â”‚
     â–¼                                                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                     â”‚
â”‚  RabbitMQ   â”‚  Queue: vkchart.scoring.requests                   â”‚
â”‚   Queue     â”‚  Message: { snapshot, request_id, priority }       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                     â”‚
     â”‚                                                              â”‚
     â”‚ [4] Consume                                                  â”‚
     â–¼                                                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚              PYTHON SCORING WORKER                           â”‚    â”‚
â”‚                                                              â”‚    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚    â”‚
â”‚  â”‚ [4.1] NORMALIZATION                                  â”‚    â”‚    â”‚
â”‚  â”‚                                                      â”‚    â”‚    â”‚
â”‚  â”‚  Input: open_area = "cta"                           â”‚    â”‚    â”‚
â”‚  â”‚    â†“                                                â”‚    â”‚    â”‚
â”‚  â”‚  Rules Engine: Check aliases_ports.yaml             â”‚    â”‚    â”‚
â”‚  â”‚    â†“ (found? â†’ return)                              â”‚    â”‚    â”‚
â”‚  â”‚  Fuzzy Match: Levenshtein distance                  â”‚    â”‚    â”‚
â”‚  â”‚    â†“ (confidence > 0.85? â†’ return)                  â”‚    â”‚    â”‚
â”‚  â”‚  LLM Fallback: "What port is 'cta'?"               â”‚    â”‚    â”‚
â”‚  â”‚    â†“                                                â”‚    â”‚    â”‚
â”‚  â”‚  Output: "ROCTA" (Constanta)                        â”‚    â”‚    â”‚
â”‚  â”‚    â†“                                                â”‚    â”‚    â”‚
â”‚  â”‚  Auto-add to pending aliases                        â”‚    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â”‚
â”‚                         â”‚                                    â”‚    â”‚
â”‚                         â–¼                                    â”‚    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚    â”‚
â”‚  â”‚ [4.2] SCORING AGENT                                  â”‚    â”‚    â”‚
â”‚  â”‚                                                      â”‚    â”‚    â”‚
â”‚  â”‚  for criterion in [P1, P1A, P2, P3, P4, P5, P6, P7]:â”‚    â”‚    â”‚
â”‚  â”‚    â”‚                                                â”‚    â”‚    â”‚
â”‚  â”‚    â”œâ”€â–º RAG: Retrieve relevant knowledge             â”‚    â”‚    â”‚
â”‚  â”‚    â”‚   (proximity_matrix, trade_patterns, etc.)     â”‚    â”‚    â”‚
â”‚  â”‚    â”‚                                                â”‚    â”‚    â”‚
â”‚  â”‚    â”œâ”€â–º Tools: Call if needed                        â”‚    â”‚    â”‚
â”‚  â”‚    â”‚   - calculate_intake(vessel, port)             â”‚    â”‚    â”‚
â”‚  â”‚    â”‚   - get_distance(port_a, port_b)               â”‚    â”‚    â”‚
â”‚  â”‚    â”‚   - parse_comments(text)                       â”‚    â”‚    â”‚
â”‚  â”‚    â”‚                                                â”‚    â”‚    â”‚
â”‚  â”‚    â”œâ”€â–º Learning: Check similar patterns             â”‚    â”‚    â”‚
â”‚  â”‚    â”‚   db.learning_patterns.find(context)           â”‚    â”‚    â”‚
â”‚  â”‚    â”‚                                                â”‚    â”‚    â”‚
â”‚  â”‚    â””â”€â–º LLM: Generate score + reasoning              â”‚    â”‚    â”‚
â”‚  â”‚        Claude: "Based on ... score is X because..." â”‚    â”‚    â”‚
â”‚  â”‚                                                      â”‚    â”‚    â”‚
â”‚  â”‚  Calculate final_score = sum(P1..P5,P7) + P6        â”‚    â”‚    â”‚
â”‚  â”‚  Apply blocking conditions                          â”‚    â”‚    â”‚
â”‚  â”‚  Generate reasoning_summary                         â”‚    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â”‚
â”‚                         â”‚                                    â”‚    â”‚
â”‚                         â–¼                                    â”‚    â”‚
â”‚  [4.3] Save to MongoDB: db.scoring_results.insert()         â”‚    â”‚
â”‚                         â”‚                                    â”‚    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
                          â”‚                                         â”‚
                          â”‚ [5] Publish Result                      â”‚
                          â–¼                                         â”‚
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚
                   â”‚  RabbitMQ   â”‚  Queue: vkchart.scoring.results â”‚
                   â”‚   Queue     â”‚  Message: { result, request_id } â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
                          â”‚                                         â”‚
                          â”‚ [6] Consume & Update                    â”‚
                          â–¼                                         â”‚
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚
                   â”‚   LARAVEL   â”‚  Update vessel_cargo_statuses   â”‚
                   â”‚  (Result)   â”‚  Broadcast to UI (Pusher)       â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 Message Generation Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       MESSAGE GENERATION DATA FLOW                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[1] User clicks "Generate Offer" or System triggers auto-generation
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LARAVEL   â”‚  Fetch: scoring_result + company + person data
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â”‚ [2] Build Message Request
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MESSAGE REQUEST                                             â”‚
â”‚  {                                                           â”‚
â”‚    scoring_result_id: ObjectId,                             â”‚
â”‚    message_type: "offer" | "reminder_1" | "whatsapp",       â”‚
â”‚    channel: "email" | "whatsapp",                           â”‚
â”‚    person: {                                                 â”‚
â”‚      name, nationality, language, comm_style,               â”‚
â”‚      timezone, previous_messages: [...]                     â”‚
â”‚    },                                                        â”‚
â”‚    company: { name, relationship_history },                 â”‚
â”‚    cargo_summary: String,                                    â”‚
â”‚    vessel_highlights: [...],                                 â”‚
â”‚    today_contact: Boolean  // ĞŸĞ¸ÑĞ°Ğ»Ğ¸ Ğ»Ğ¸ ÑĞµĞ³Ğ¾Ğ´Ğ½Ñ?            â”‚
â”‚  }                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â”‚ [3] Publish to Queue
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RabbitMQ   â”‚  Queue: vkchart.messages.requests
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â”‚ [4] Consume
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PYTHON MESSAGE WORKER                           â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ [4.1] LOAD CONTEXT                                   â”‚    â”‚
â”‚  â”‚                                                      â”‚    â”‚
â”‚  â”‚  - Fetch scoring_result from MongoDB                 â”‚    â”‚
â”‚  â”‚  - Load appropriate template                         â”‚    â”‚
â”‚  â”‚  - Load previous messages with this person           â”‚    â”‚
â”‚  â”‚  - Load person's communication preferences           â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                         â”‚                                    â”‚
â”‚                         â–¼                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ [4.2] MESSAGE AGENT                                  â”‚    â”‚
â”‚  â”‚                                                      â”‚    â”‚
â”‚  â”‚  System Prompt:                                      â”‚    â”‚
â”‚  â”‚  "You are Vitaly, a maritime freight broker.        â”‚    â”‚
â”‚  â”‚   Write personalized, professional messages.        â”‚    â”‚
â”‚  â”‚   Match the tone to the recipient's style.          â”‚    â”‚
â”‚  â”‚   Use scoring insights to highlight key points."    â”‚    â”‚
â”‚  â”‚                                                      â”‚    â”‚
â”‚  â”‚  Context Injection:                                  â”‚    â”‚
â”‚  â”‚  - Scoring reasoning (strengths, weaknesses)        â”‚    â”‚
â”‚  â”‚  - Company relationship history                     â”‚    â”‚
â”‚  â”‚  - Person's preferred communication style           â”‚    â”‚
â”‚  â”‚  - Previous message thread (if reminder)            â”‚    â”‚
â”‚  â”‚  - Today's contact flag (skip greeting if true)     â”‚    â”‚
â”‚  â”‚                                                      â”‚    â”‚
â”‚  â”‚  Template Selection:                                 â”‚    â”‚
â”‚  â”‚  - Score â‰¥ 85: case_a_strong_match.txt              â”‚    â”‚
â”‚  â”‚  - Score 70-84: case_a_standard.txt                 â”‚    â”‚
â”‚  â”‚  - Score 60-69: case_b_not_ideal.txt                â”‚    â”‚
â”‚  â”‚  - Reminder: reminder_{n}.txt                       â”‚    â”‚
â”‚  â”‚                                                      â”‚    â”‚
â”‚  â”‚  LLM Generation:                                     â”‚    â”‚
â”‚  â”‚  Claude â†’ Personalized message text                 â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                         â”‚                                    â”‚
â”‚                         â–¼                                    â”‚
â”‚  [4.3] Save to MongoDB: db.message_history.insert()         â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â”‚ [5] Return to Laravel
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LARAVEL   â”‚  Show in UI for approval
â”‚     UI      â”‚  User can edit â†’ Save edited version
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â”‚ [6] On Send
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LARAVEL   â”‚  Send via Gmail API / WhatsApp API
â”‚   Sender    â”‚  Update message_history (sent_at)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 5. API CONTRACTS

### 5.1 Internal API (Laravel â†” Python)

```yaml
# FastAPI Endpoints

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SCORING ENDPOINTS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

POST /api/v1/scoring/calculate:
  description: "Calculate scoring for vessel-cargo pair"
  request:
    content-type: application/json
    body:
      vessel:
        id: integer
        name: string
        imo: string
        dwt: integer
        flag: string
        built_year: integer
        open_area: string
        open_port: string
        open_date: date
        destination: string
        eta: datetime
        current_position:
          lat: float
          lon: float
        comments: string
        last_ports: 
          - port: string
            percentage: float
      cargo:
        id: integer
        type: string
        quantity: integer
        stowage_factor: float
        load_port: string
        load_region: string
        disch_port: string
        disch_region: string
        laycan_start: date
        laycan_end: date
        loading_rate: integer
      company:
        id: integer
        name: string
        comments: string
        regional_preferences:
          - region: string
            preference: string  # specializes|prefers|can_work|neutral|avoids|cannot
        cargo_preferences:
          - cargo_type: string
            preference: string
      person:
        id: integer
        name: string
        comments: string
      request_id: string
      priority: string  # high|normal|low
      
  response:
    200:
      scoring_result_id: string  # MongoDB ObjectId
      request_id: string
      final_score: integer
      classification: string
      is_blocked: boolean
      block_reason: string
      scores:
        p1_proximity:
          score: integer
          max_score: 20
          reasoning: string
        p1a_patterns:
          score: integer
          max_score: 15
          reasoning: string
        # ... all P1-P7
      reasoning_summary: string
      strengths: [string]
      weaknesses: [string]
      recommendation: string
      metadata:
        processing_time_ms: integer
        model_used: string
        
GET /api/v1/scoring/{scoring_result_id}:
  description: "Get scoring result by ID"
  response:
    200: ScoringResult

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MESSAGE ENDPOINTS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

POST /api/v1/messages/generate:
  description: "Generate message based on scoring"
  request:
    scoring_result_id: string
    message_type: string  # offer|reminder_1|reminder_2|reminder_3|whatsapp
    channel: string  # email|whatsapp|teams
    person:
      id: integer
      name: string
      nationality: string
      language: string
      comm_style: string  # formal|informal|brief
      timezone: string
    previous_messages: 
      - text: string
        sent_at: datetime
        response: string
    today_contact: boolean
    
  response:
    200:
      message_id: string
      generated_text: string
      subject: string  # for emails
      personalization_notes: string
      
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# NORMALIZATION ENDPOINTS  
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

POST /api/v1/normalize:
  description: "Normalize entity value"
  request:
    entity_type: string  # port|region|cargo
    value: string
    context:
      vessel_id: integer
      cargo_id: integer
      
  response:
    200:
      original: string
      normalized: string
      confidence: float
      method: string  # exact|fuzzy|llm
      auto_added: boolean

GET /api/v1/normalize/pending:
  description: "Get pending alias approvals"
  response:
    200:
      items:
        - id: string
          entity_type: string
          original: string
          normalized: string
          confidence: float
          created_at: datetime

POST /api/v1/normalize/review/{id}:
  description: "Approve or reject auto-added alias"
  request:
    action: string  # approve|reject
    rejection_reason: string  # if reject
    correct_value: string  # if reject with correction
    
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LEARNING ENDPOINTS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

POST /api/v1/learning/feedback:
  description: "Submit user correction"
  request:
    scoring_result_id: string
    feedback_type: string  # score_correction|text_edit
    original_value: any
    corrected_value: any
    user_explanation: string
    user_id: integer
    
  response:
    200:
      pattern_id: string
      similar_patterns_found: integer
      
GET /api/v1/learning/stats:
  description: "Get learning statistics"
  response:
    200:
      total_corrections: integer
      accuracy_improvement: float
      patterns_by_criterion:
        p1: integer
        p2: integer
        # ...

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# HEALTH & MONITORING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

GET /health:
  response:
    200:
      status: string
      mongodb: string
      rabbitmq: string
      llm_api: string
      
GET /metrics:
  response:
    200:
      scoring_requests_total: integer
      scoring_avg_time_ms: float
      message_requests_total: integer
      llm_calls_today: integer
      llm_cost_today_usd: float
```

### 5.2 RabbitMQ Message Schemas

```json
// Queue: vkchart.scoring.requests
{
  "request_id": "uuid",
  "priority": "high|normal|low",
  "timestamp": "2024-11-30T10:00:00Z",
  "payload": {
    "vessel": { ... },
    "cargo": { ... },
    "company": { ... },
    "person": { ... }
  }
}

// Queue: vkchart.scoring.results
{
  "request_id": "uuid",
  "success": true,
  "timestamp": "2024-11-30T10:00:05Z",
  "result": {
    "scoring_result_id": "mongo_object_id",
    "final_score": 78,
    "classification": "good",
    "is_blocked": false
  },
  "error": null
}

// Queue: vkchart.normalize.logs
{
  "timestamp": "2024-11-30T10:00:00Z",
  "action": "auto_add",
  "entity_type": "port",
  "original": "cta",
  "normalized": "ROCTA",
  "confidence": 0.92,
  "requires_review": true
}

// Queue: vkchart.learning.feedback
{
  "timestamp": "2024-11-30T10:00:00Z",
  "scoring_result_id": "mongo_object_id",
  "feedback_type": "score_correction",
  "criterion": "P1",
  "original_score": 15,
  "corrected_score": 8,
  "user_explanation": "Vessel is too far, Libya to Black Sea is not profitable for Handysize",
  "user_id": 1
}
```

---

## 6. DATABASE SCHEMA

### 6.1 MySQL Tables (Laravel)

```sql
-- Existing tables used:
-- vessels, cargos, companies, people, ports, vessel_cargo_statuses

-- NEW TABLES:

-- Scoring results reference (main data in MongoDB)
CREATE TABLE scoring_results (
    id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY,
    mongo_id VARCHAR(24) NOT NULL UNIQUE,
    vessel_id BIGINT UNSIGNED NOT NULL,
    cargo_id BIGINT UNSIGNED NOT NULL,
    final_score TINYINT UNSIGNED NOT NULL,
    classification ENUM('excellent','good','acceptable','marginal','poor','blocked') NOT NULL,
    is_blocked BOOLEAN DEFAULT FALSE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    INDEX idx_vessel_cargo (vessel_id, cargo_id),
    INDEX idx_cargo_score (cargo_id, final_score DESC),
    INDEX idx_created (created_at),
    
    FOREIGN KEY (vessel_id) REFERENCES vessels(id),
    FOREIGN KEY (cargo_id) REFERENCES cargos(id)
);

-- Learning feedback tracking
CREATE TABLE learning_feedbacks (
    id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY,
    scoring_result_id BIGINT UNSIGNED NOT NULL,
    feedback_type ENUM('score_correction','text_edit','alias_approval') NOT NULL,
    criterion VARCHAR(10),  -- P1, P2, etc.
    original_value TEXT,
    corrected_value TEXT,
    user_explanation TEXT,
    user_id BIGINT UNSIGNED NOT NULL,
    processed BOOLEAN DEFAULT FALSE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    INDEX idx_scoring (scoring_result_id),
    INDEX idx_user (user_id),
    
    FOREIGN KEY (scoring_result_id) REFERENCES scoring_results(id),
    FOREIGN KEY (user_id) REFERENCES users(id)
);

-- Normalization audit log
CREATE TABLE normalization_logs (
    id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY,
    entity_type ENUM('port','region','cargo','vessel_size') NOT NULL,
    original_value VARCHAR(255) NOT NULL,
    normalized_value VARCHAR(255) NOT NULL,
    method ENUM('exact','fuzzy','llm') NOT NULL,
    confidence DECIMAL(3,2),
    auto_added BOOLEAN DEFAULT FALSE,
    status ENUM('pending','approved','rejected') DEFAULT 'approved',
    reviewed_by BIGINT UNSIGNED,
    reviewed_at TIMESTAMP,
    rejection_reason TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    INDEX idx_entity (entity_type, original_value),
    INDEX idx_status (status),
    
    FOREIGN KEY (reviewed_by) REFERENCES users(id)
);

-- AI job queue tracking
CREATE TABLE ai_jobs (
    id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY,
    job_type ENUM('scoring','message','normalize','learning') NOT NULL,
    request_id VARCHAR(36) NOT NULL UNIQUE,
    vessel_id BIGINT UNSIGNED,
    cargo_id BIGINT UNSIGNED,
    status ENUM('pending','processing','completed','failed') DEFAULT 'pending',
    priority ENUM('high','normal','low') DEFAULT 'normal',
    attempts TINYINT UNSIGNED DEFAULT 0,
    error_message TEXT,
    processing_time_ms INT UNSIGNED,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    started_at TIMESTAMP,
    completed_at TIMESTAMP,
    
    INDEX idx_status (status, priority),
    INDEX idx_request (request_id),
    INDEX idx_vessel_cargo (vessel_id, cargo_id)
);
```

### 6.2 MongoDB Collections (detailed in Section 3.4)

See Section 3.4 for full MongoDB schema.

---

## 7. AI AGENTS DESIGN

### 7.1 Scoring Agent

```python
# app/agents/scoring_agent.py

from langchain.agents import AgentExecutor, create_structured_chat_agent
from langchain.prompts import ChatPromptTemplate
from langchain_anthropic import ChatAnthropic

class ScoringAgent:
    """
    Agent responsible for vessel-cargo scoring.
    Calculates P1-P7 criteria and generates reasoning.
    """
    
    SYSTEM_PROMPT = """You are an expert maritime freight broker scoring system.
Your task is to evaluate vessel-cargo compatibility across 7 criteria.

SCORING CRITERIA:
- P1 Proximity (0-20): Geographic distance from vessel to loading port
- P1A Regional Patterns (0-15): Market logic of vessel positioning
- P2 Regional Preferences (0-15): Owner's regional preferences from comments
- P3 Cargo Preferences (0-15): Cargo type compatibility
- P4 Last Ports (0-10): Vessel's familiarity with region
- P5 Intake Capacity (0-15): Ability to load required quantity
- P6 OpenArea Comments (-50 to +25): Current voyage preferences (MODIFIER)
- P7 Readiness (0-10): Timing match with laycan

RULES:
1. Use provided knowledge base for scoring rules
2. Call tools when calculation is needed (intake, distance)
3. Check learning patterns for similar cases
4. Generate clear reasoning for each criterion
5. Apply blocking conditions when necessary

BLOCKING CONDITIONS:
- Technical impossibility (intake < 90% of cargo)
- P6 â‰¤ -40 (owner explicitly avoids)
- Geopolitical restrictions (sanctions)

OUTPUT FORMAT:
Return JSON with scores, reasoning, and recommendation.
"""

    def __init__(self, llm_client, tools, knowledge_retriever, learning_db):
        self.llm = llm_client
        self.tools = tools
        self.knowledge = knowledge_retriever
        self.learning = learning_db
        
        self.agent = self._build_agent()
    
    def _build_agent(self):
        prompt = ChatPromptTemplate.from_messages([
            ("system", self.SYSTEM_PROMPT),
            ("human", "{input}"),
            ("placeholder", "{agent_scratchpad}")
        ])
        
        return create_structured_chat_agent(
            llm=self.llm,
            tools=self.tools,
            prompt=prompt
        )
    
    async def score(self, snapshot: dict) -> dict:
        """
        Main scoring method.
        
        Args:
            snapshot: Dict with vessel, cargo, company, person data
            
        Returns:
            Dict with scores, reasoning, recommendation
        """
        # 1. Retrieve relevant knowledge
        knowledge_context = await self._get_knowledge_context(snapshot)
        
        # 2. Check for similar learned patterns
        similar_patterns = await self._find_similar_patterns(snapshot)
        
        # 3. Build input for agent
        agent_input = self._build_input(
            snapshot, 
            knowledge_context, 
            similar_patterns
        )
        
        # 4. Execute agent
        executor = AgentExecutor(
            agent=self.agent,
            tools=self.tools,
            verbose=True,
            max_iterations=10
        )
        
        result = await executor.ainvoke({"input": agent_input})
        
        # 5. Parse and validate result
        scoring_result = self._parse_result(result)
        
        return scoring_result
    
    async def _get_knowledge_context(self, snapshot: dict) -> dict:
        """Retrieve relevant knowledge chunks via RAG."""
        queries = {
            "P1": f"proximity scoring {snapshot['cargo']['load_region']}",
            "P1A": f"trade patterns {snapshot['vessel']['open_area']} to {snapshot['cargo']['load_region']}",
            "P2": f"regional preferences {snapshot['company']['name']}",
            "P3": f"cargo preferences {snapshot['cargo']['type']}",
            "P5": f"intake calculation {snapshot['cargo']['load_port']}",
            "P6": f"open area comments interpretation",
            "P7": f"readiness timing laycan"
        }
        
        context = {}
        for criterion, query in queries.items():
            docs = await self.knowledge.aretrieve(query, k=3)
            context[criterion] = [doc.page_content for doc in docs]
        
        return context
    
    async def _find_similar_patterns(self, snapshot: dict) -> list:
        """Find similar learned patterns from corrections."""
        return await self.learning.find_similar({
            "vessel_type": self._get_vessel_type(snapshot['vessel']['dwt']),
            "cargo_type": snapshot['cargo']['type'],
            "region_from": snapshot['vessel']['open_area'],
            "region_to": snapshot['cargo']['load_region']
        }, limit=5)
    
    def _build_input(self, snapshot, knowledge, patterns) -> str:
        """Build comprehensive input string for agent."""
        return f"""
SCORING REQUEST:

VESSEL: {snapshot['vessel']['name']} ({snapshot['vessel']['dwt']} DWT)
- Open: {snapshot['vessel']['open_area']} on {snapshot['vessel']['open_date']}
- Destination: {snapshot['vessel']['destination']} ETA {snapshot['vessel']['eta']}
- Comments: {snapshot['vessel']['comments']}

CARGO: {snapshot['cargo']['type']} {snapshot['cargo']['quantity']}t
- Load: {snapshot['cargo']['load_port']} ({snapshot['cargo']['load_region']})
- Disch: {snapshot['cargo']['disch_port']}
- Laycan: {snapshot['cargo']['laycan_start']} - {snapshot['cargo']['laycan_end']}

COMPANY: {snapshot['company']['name']}
- Comments: {snapshot['company']['comments']}
- Preferences: {snapshot['company'].get('preferences', 'None specified')}

KNOWLEDGE BASE CONTEXT:
{self._format_knowledge(knowledge)}

SIMILAR LEARNED PATTERNS:
{self._format_patterns(patterns)}

Calculate scores for all criteria P1-P7 with reasoning.
"""
```

### 7.2 Message Agent

```python
# app/agents/message_agent.py

class MessageAgent:
    """
    Agent responsible for generating personalized messages.
    """
    
    SYSTEM_PROMPT = """You are Vitaly Kravets, a professional maritime freight broker.
Write personalized, engaging messages to shipowners.

PERSONALITY:
- Professional but warm
- Direct and efficient
- Knowledgeable about market
- Respectful of recipient's time

RULES:
1. Match recipient's communication style (formal/informal)
2. Use scoring insights to highlight relevant points
3. If today_contact=True, skip greeting (continuing thread)
4. Keep WhatsApp messages shorter than emails
5. Include vessel name and key cargo details
6. For reminders, reference previous message naturally

TEMPLATES AVAILABLE:
- Strong match (score â‰¥85): Enthusiastic, highlight perfect fit
- Good match (70-84): Professional, mention strengths
- Acceptable (60-69): Balanced, acknowledge caveats
- Reminder: Gentle follow-up, add new info if available

PERSONALIZATION FACTORS:
- Nationality â†’ Cultural nuances
- Previous messages â†’ Continuity
- Relationship history â†’ Familiarity level
"""

    def __init__(self, llm_client, template_loader):
        self.llm = llm_client
        self.templates = template_loader
    
    async def generate(self, request: dict) -> dict:
        """
        Generate personalized message.
        
        Args:
            request: Dict with scoring_result, person, message_type, etc.
        """
        # 1. Load appropriate template
        template = self._select_template(
            request['message_type'],
            request['scoring_result']['final_score']
        )
        
        # 2. Build personalization context
        context = self._build_context(request)
        
        # 3. Generate message
        prompt = f"""
{self.SYSTEM_PROMPT}

TEMPLATE STRUCTURE:
{template}

CONTEXT:
{context}

Generate the message now. Return JSON with:
- subject (for email)
- body
- personalization_notes (what you customized)
"""
        
        response = await self.llm.ainvoke(prompt)
        
        return self._parse_response(response)
    
    def _select_template(self, message_type: str, score: int) -> str:
        """Select appropriate template based on type and score."""
        if message_type.startswith("reminder"):
            return self.templates.get(f"reminder_{message_type[-1]}")
        
        if score >= 85:
            return self.templates.get("case_a_strong_match")
        elif score >= 70:
            return self.templates.get("case_a_standard")
        elif score >= 60:
            return self.templates.get("case_b_not_ideal")
        else:
            return self.templates.get("case_b_positioning")
    
    def _build_context(self, request: dict) -> str:
        """Build personalization context string."""
        scoring = request['scoring_result']
        person = request['person']
        
        return f"""
RECIPIENT:
- Name: {person['name']}
- Nationality: {person['nationality']}
- Style: {person['comm_style']}
- Language: {person['language']}

SCORING INSIGHTS:
- Final Score: {scoring['final_score']}/100
- Strengths: {', '.join(scoring['strengths'])}
- Weaknesses: {', '.join(scoring['weaknesses'])}
- Recommendation: {scoring['recommendation']}

VESSEL HIGHLIGHTS:
{scoring['reasoning_summary']}

PREVIOUS MESSAGES:
{self._format_previous(request.get('previous_messages', []))}

TODAY CONTACT: {request.get('today_contact', False)}
CHANNEL: {request['channel']}
"""
```

### 7.3 Tools Definition

```python
# app/tools/intake_calculator.py

from langchain.tools import tool
from typing import Dict

@tool
def calculate_intake(
    vessel_dwt: int,
    vessel_summer_draft: float,
    port_draft_limit: float,
    water_density: float = 1.025,
    cargo_stowage_factor: float = None,
    vessel_grain_cubic: float = None
) -> Dict:
    """
    Calculate maximum cargo intake for vessel at specific port.
    
    Args:
        vessel_dwt: Vessel deadweight tonnage
        vessel_summer_draft: Summer draft in meters
        port_draft_limit: Port draft limitation in meters
        water_density: Water density (1.025 for salt, 1.000 for fresh)
        cargo_stowage_factor: Cargo SF in cbft/t (optional)
        vessel_grain_cubic: Vessel grain capacity in mÂ³ (optional)
    
    Returns:
        Dict with intake_weight, intake_volume, limiting_factor
    """
    # Constants
    UKC = 0.5  # Under keel clearance
    SQUAT = 0.3  # Squat allowance
    ROB_FACTOR = 0.04  # 4% for bunkers/stores
    
    # 1. Calculate TPC (tonnes per cm)
    lpp_estimated = vessel_summer_draft * 20  # Rough estimation
    cwp = 0.85  # Block coefficient for bulk carriers
    tpc_salt = (lpp_estimated * (vessel_dwt / 10000) * 10 * cwp * 1.025) / 100
    
    # 2. Calculate allowable draft
    t_allow = port_draft_limit - UKC - SQUAT
    
    # 3. Density correction
    if water_density < 1.025:
        fwa = (vessel_dwt / (4 * tpc_salt * 10)) * 100  # in cm
        density_factor = (1.025 - water_density) / 0.025
        t_allow_sw = t_allow + (fwa * density_factor / 100)
    else:
        t_allow_sw = t_allow
    
    # 4. Draft reduction needed
    dt = max(0, vessel_summer_draft - t_allow_sw)
    loss_tonnes = dt * 100 * tpc_salt
    
    # 5. Weight-limited intake
    intake_weight = vessel_dwt - loss_tonnes - (vessel_dwt * ROB_FACTOR)
    
    # 6. Volume-limited intake (if data available)
    intake_volume = None
    if cargo_stowage_factor and vessel_grain_cubic:
        sf_m3 = cargo_stowage_factor * 0.0283168  # cbft to mÂ³
        intake_volume = vessel_grain_cubic / sf_m3
    
    # 7. Final intake
    if intake_volume:
        final_intake = min(intake_weight, intake_volume)
        limiting = "volume" if intake_volume < intake_weight else "weight"
    else:
        final_intake = intake_weight
        limiting = "weight"
    
    return {
        "intake_weight": round(intake_weight),
        "intake_volume": round(intake_volume) if intake_volume else None,
        "intake_final": round(final_intake),
        "limiting_factor": limiting,
        "draft_reduction_m": round(dt, 2),
        "tonnage_lost": round(loss_tonnes)
    }


@tool
def estimate_distance(
    lat1: float, lon1: float,
    lat2: float, lon2: float,
    route_type: str = "direct"
) -> Dict:
    """
    Estimate sea distance between two points.
    
    Args:
        lat1, lon1: Origin coordinates
        lat2, lon2: Destination coordinates
        route_type: "direct", "via_suez", "via_gibraltar"
    
    Returns:
        Dict with distance_nm, estimated_days, route_notes
    """
    import math
    
    # Haversine formula
    R = 3440.065  # Earth radius in nautical miles
    
    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])
    dlat = lat2 - lat1
    dlon = lon2 - lon1
    
    a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2
    c = 2 * math.asin(math.sqrt(a))
    
    direct_distance = R * c
    
    # Apply route factor (sea routes are longer than great circle)
    route_factors = {
        "direct": 1.15,
        "via_suez": 1.3,
        "via_gibraltar": 1.25
    }
    
    distance = direct_distance * route_factors.get(route_type, 1.15)
    
    # Estimate sailing days (12 knots average)
    days = distance / (12 * 24)
    
    return {
        "distance_nm": round(distance),
        "estimated_days": round(days, 1),
        "route_type": route_type,
        "is_estimate": True,
        "note": "Calculated from coordinates. Actual distance may vary."
    }


@tool
def parse_comments(
    comments: str,
    comment_type: str = "vessel"
) -> Dict:
    """
    Parse structured information from free-text comments.
    
    Args:
        comments: Raw comment text
        comment_type: "vessel", "company", "person", "open_area"
    
    Returns:
        Dict with extracted preferences, restrictions, technical data
    """
    import re
    
    result = {
        "specialization": [],
        "geographic_preferences": [],
        "cargo_preferences": [],
        "technical_data": {},
        "communication_notes": [],
        "raw_text": comments
    }
    
    if not comments:
        return result
    
    comments_lower = comments.lower()
    
    # Geographic preferences
    geo_patterns = [
        (r"(spec|specializes?)[\s:]+(.+?)(?:,|$)", "specializes"),
        (r"(\w+)\s+ok", "can_work"),
        (r"no\s+(\w+)", "avoids"),
        (r"cannot\s+(\w+)", "cannot"),
        (r"prefers?\s+(\w+)", "prefers")
    ]
    
    for pattern, pref_type in geo_patterns:
        matches = re.findall(pattern, comments_lower)
        for match in matches:
            value = match[1] if isinstance(match, tuple) else match
            result["geographic_preferences"].append({
                "region": value.strip(),
                "preference": pref_type
            })
    
    # Intake data
    intake_pattern = r"(?:real\s+)?intake[:\s]+(\w+)[,\s]+(?:draft\s+)?(\d+(?:\.\d+)?)\s*m[,\s]+(\w+)\s*=\s*(\d+)\s*t"
    intake_match = re.search(intake_pattern, comments_lower)
    if intake_match:
        result["technical_data"]["manual_intake"] = {
            "cargo": intake_match.group(1),
            "draft": float(intake_match.group(2)),
            "port": intake_match.group(3),
            "tonnage": int(intake_match.group(4))
        }
    
    # Cargo preferences
    cargo_patterns = [
        (r"no\s+(grains?|steel|fertilizers?)", "avoids"),
        (r"(grains?|steel|fertilizers?)\s+only", "specializes"),
        (r"prefers?\s+(grains?|steel|fertilizers?)", "prefers")
    ]
    
    for pattern, pref_type in cargo_patterns:
        matches = re.findall(pattern, comments_lower)
        for match in matches:
            result["cargo_preferences"].append({
                "cargo_type": match,
                "preference": pref_type
            })
    
    return result
```

---

## 8. KNOWLEDGE BASE STRUCTURE

### 8.1 File Organization

```
knowledge_base/
â”œâ”€â”€ scoring/
â”‚   â”œâ”€â”€ proximity_scoring_matrix.yaml      # P1 rules
â”‚   â”œâ”€â”€ regional_trade_patterns.yaml       # P1A rules
â”‚   â”œâ”€â”€ comments_processing_guide.yaml     # P2, P3 rules
â”‚   â”œâ”€â”€ intake_calculator_formula.yaml     # P5 rules
â”‚   â”œâ”€â”€ open_area_comments_scoring.yaml    # P6 rules
â”‚   â””â”€â”€ readiness_eta_scoring.yaml         # P7 rules
â”‚
â”œâ”€â”€ reference/
â”‚   â”œâ”€â”€ vessel_size_classification.yaml
â”‚   â”œâ”€â”€ vessel_location_determination.yaml
â”‚   â”œâ”€â”€ port_restrictions_map.yaml
â”‚   â””â”€â”€ cargo_export_map.yaml
â”‚
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ email/
â”‚   â”‚   â”œâ”€â”€ case_a_strong_match.txt
â”‚   â”‚   â”œâ”€â”€ case_a_standard.txt
â”‚   â”‚   â”œâ”€â”€ case_b_not_ideal.txt
â”‚   â”‚   â”œâ”€â”€ case_b_positioning.txt
â”‚   â”‚   â”œâ”€â”€ reminder_1.txt
â”‚   â”‚   â”œâ”€â”€ reminder_2.txt
â”‚   â”‚   â””â”€â”€ reminder_3.txt
â”‚   â””â”€â”€ whatsapp/
â”‚       â”œâ”€â”€ offer_short.txt
â”‚       â””â”€â”€ reminder_short.txt
â”‚
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ scoring_examples.yaml
â”‚   â”œâ”€â”€ message_examples.yaml
â”‚   â””â”€â”€ edge_cases.yaml
â”‚
â””â”€â”€ learning/
    â””â”€â”€ learned_patterns.yaml  # Updated by system
```

### 8.2 RAG Configuration

```python
# app/knowledge/rag_retriever.py

from langchain_mongodb import MongoDBAtlasVectorSearch
from langchain_openai import OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter

class KnowledgeRetriever:
    """
    RAG-based knowledge retrieval from MongoDB Atlas.
    """
    
    def __init__(self, mongo_collection, embedding_model="text-embedding-3-small"):
        self.embeddings = OpenAIEmbeddings(model=embedding_model)
        self.vector_store = MongoDBAtlasVectorSearch(
            collection=mongo_collection,
            embedding=self.embeddings,
            index_name="vector_index",
            text_key="chunk_text",
            embedding_key="embedding"
        )
        self.splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=50,
            separators=["\n\n", "\n", ". ", " "]
        )
    
    async def ingest_file(self, file_path: str, metadata: dict):
        """Ingest knowledge file into vector store."""
        with open(file_path, 'r') as f:
            content = f.read()
        
        chunks = self.splitter.split_text(content)
        
        documents = []
        for i, chunk in enumerate(chunks):
            documents.append({
                "chunk_text": chunk,
                "chunk_id": f"{file_path}_{i}",
                "source_file": file_path,
                "metadata": metadata
            })
        
        await self.vector_store.aadd_documents(documents)
    
    async def aretrieve(self, query: str, k: int = 5, filter: dict = None) -> list:
        """Retrieve relevant knowledge chunks."""
        return await self.vector_store.asimilarity_search(
            query,
            k=k,
            pre_filter=filter
        )
    
    async def retrieve_by_criterion(self, criterion: str, context: str, k: int = 3) -> list:
        """Retrieve knowledge specific to a scoring criterion."""
        return await self.aretrieve(
            query=context,
            k=k,
            filter={"metadata.criterion": criterion}
        )
```

---

## 9. NORMALIZATION SYSTEM

### 9.1 Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        NORMALIZATION PIPELINE                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Input: "cta" (from vessel.open_area)
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: EXACT MATCH                                          â”‚
â”‚                                                              â”‚
â”‚ Check: aliases/ports_aliases.yaml                            â”‚
â”‚ {                                                            â”‚
â”‚   "cta": "ROCTA",                                           â”‚
â”‚   "konstanza": "ROCTA",                                     â”‚
â”‚   "constancia": "ROCTA",                                    â”‚
â”‚   ...                                                        â”‚
â”‚ }                                                            â”‚
â”‚                                                              â”‚
â”‚ Found? â†’ Return "ROCTA" (confidence: 1.0)                   â”‚
â”‚ Not found? â†’ Continue                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Not found
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: FUZZY MATCH                                          â”‚
â”‚                                                              â”‚
â”‚ Algorithm: Levenshtein distance + phonetic matching          â”‚
â”‚ Threshold: similarity > 0.85                                 â”‚
â”‚                                                              â”‚
â”‚ Check against all known values:                              â”‚
â”‚ - "cta" vs "constanta" â†’ similarity: 0.62 âŒ                â”‚
â”‚ - "cta" vs "catania" â†’ similarity: 0.71 âŒ                  â”‚
â”‚                                                              â”‚
â”‚ Best match > 0.85? â†’ Return with confidence                  â”‚
â”‚ No match? â†’ Continue                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ No match
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: LLM FALLBACK                                         â”‚
â”‚                                                              â”‚
â”‚ Prompt to Claude:                                            â”‚
â”‚ "In maritime shipping context, what port does 'cta' refer   â”‚
â”‚  to? Options: [list of known ports in region]               â”‚
â”‚  Return the UNLOCODE and confidence level."                 â”‚
â”‚                                                              â”‚
â”‚ Response: {"port": "Constanta", "unlocode": "ROCTA",        â”‚
â”‚            "confidence": 0.92}                               â”‚
â”‚                                                              â”‚
â”‚ Confidence > 0.7? â†’ Accept and continue                      â”‚
â”‚ Confidence â‰¤ 0.7? â†’ Flag for manual review                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Accepted
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 4: AUTO-ADD ALIAS                                       â”‚
â”‚                                                              â”‚
â”‚ 1. Add to MongoDB: aliases_auto collection                   â”‚
â”‚    {                                                         â”‚
â”‚      entity_type: "port",                                   â”‚
â”‚      original_value: "cta",                                 â”‚
â”‚      normalized_value: "ROCTA",                             â”‚
â”‚      source: "llm_fallback",                                â”‚
â”‚      confidence: 0.92,                                      â”‚
â”‚      status: "pending"                                      â”‚
â”‚    }                                                         â”‚
â”‚                                                              â”‚
â”‚ 2. Publish to queue: vkchart.normalize.logs                 â”‚
â”‚    â†’ Laravel receives notification                           â”‚
â”‚    â†’ Shows in "Pending Aliases" UI                          â”‚
â”‚                                                              â”‚
â”‚ 3. User reviews:                                             â”‚
â”‚    - Approve â†’ Move to ports_aliases.yaml                   â”‚
â”‚    - Reject â†’ Log reason, don't use again                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
Output: "ROCTA" (Constanta)
```

### 9.2 Implementation

```python
# app/normalizers/port_normalizer.py

from rapidfuzz import fuzz, process
from typing import Optional, Tuple

class PortNormalizer:
    """
    Multi-stage port name normalizer.
    """
    
    def __init__(self, aliases_path: str, llm_client, mongo_client):
        self.aliases = self._load_aliases(aliases_path)
        self.llm = llm_client
        self.mongo = mongo_client
        
        # Known ports for fuzzy matching
        self.known_ports = list(self.aliases.values())
    
    async def normalize(
        self, 
        value: str, 
        context: dict = None
    ) -> Tuple[str, float, str]:
        """
        Normalize port name.
        
        Returns:
            Tuple of (normalized_value, confidence, method)
        """
        value_lower = value.lower().strip()
        
        # Step 1: Exact match
        if value_lower in self.aliases:
            return self.aliases[value_lower], 1.0, "exact"
        
        # Step 2: Fuzzy match
        fuzzy_result = self._fuzzy_match(value_lower)
        if fuzzy_result:
            return fuzzy_result
        
        # Step 3: LLM fallback
        llm_result = await self._llm_normalize(value, context)
        if llm_result[1] > 0.7:  # confidence threshold
            await self._auto_add_alias(value_lower, llm_result[0], llm_result[1], context)
        
        return llm_result
    
    def _fuzzy_match(self, value: str) -> Optional[Tuple[str, float, str]]:
        """Try fuzzy matching against known ports."""
        # Check aliases keys first
        alias_match = process.extractOne(
            value,
            self.aliases.keys(),
            scorer=fuzz.ratio,
            score_cutoff=85
        )
        
        if alias_match:
            return self.aliases[alias_match[0]], alias_match[1] / 100, "fuzzy"
        
        return None
    
    async def _llm_normalize(
        self, 
        value: str, 
        context: dict
    ) -> Tuple[str, float, str]:
        """Use LLM to interpret unknown port name."""
        # Get regional context if available
        region_hint = ""
        if context and context.get("vessel_open_area"):
            region_hint = f"The vessel is in {context['vessel_open_area']} region."
        
        prompt = f"""
In maritime shipping, what port does "{value}" refer to?
{region_hint}

Known ports in this context:
{self._get_regional_ports(context)}

Return JSON:
{{
  "port_name": "Full port name",
  "unlocode": "XXYYY format",
  "confidence": 0.0-1.0,
  "reasoning": "Why this match"
}}

If uncertain, set confidence below 0.7.
"""
        
        response = await self.llm.ainvoke(prompt)
        result = self._parse_llm_response(response)
        
        return result["unlocode"], result["confidence"], "llm"
    
    async def _auto_add_alias(
        self, 
        original: str, 
        normalized: str, 
        confidence: float,
        context: dict
    ):
        """Add new alias for review."""
        await self.mongo.aliases_auto.insert_one({
            "entity_type": "port",
            "original_value": original,
            "normalized_value": normalized,
            "source": "llm_fallback",
            "confidence": confidence,
            "context": context,
            "status": "pending",
            "created_at": datetime.utcnow()
        })
        
        # Publish notification
        await self._notify_new_alias(original, normalized, confidence)
```

---

## 10. LEARNING MECHANISM

### 10.1 Feedback Loop

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           LEARNING FEEDBACK LOOP                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[1] AI generates scoring result
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   UI Shows  â”‚  Score: 72/100
â”‚   Results   â”‚  P1: 15, P2: 10, P3: 12...
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ [2] User reviews
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ USER ACTION                                                  â”‚
â”‚                                                              â”‚
â”‚ Option A: Approve âœ“                                         â”‚
â”‚   â†’ Score confirmed                                          â”‚
â”‚   â†’ Increase confidence in similar patterns                  â”‚
â”‚                                                              â”‚
â”‚ Option B: Correct âœ                                         â”‚
â”‚   â†’ User changes P1 from 15 to 8                            â”‚
â”‚   â†’ System asks: "Why should P1 be lower?"                  â”‚
â”‚   â†’ User: "Libya to Black Sea is not profitable for Handy"  â”‚
â”‚                                                              â”‚
â”‚ Option C: Skip âœ—                                            â”‚
â”‚   â†’ Don't send offer                                         â”‚
â”‚   â†’ Optional: explain why                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ [3] If corrected
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PATTERN EXTRACTION                                           â”‚
â”‚                                                              â”‚
â”‚ System analyzes:                                             â”‚
â”‚ - What was different?                                        â”‚
â”‚ - What context led to error?                                 â”‚
â”‚ - Is there a pattern?                                        â”‚
â”‚                                                              â”‚
â”‚ Extracted pattern:                                           â”‚
â”‚ {                                                            â”‚
â”‚   "context": {                                              â”‚
â”‚     "vessel_type": "Handysize",                            â”‚
â”‚     "region_from": "Libya",                                â”‚
â”‚     "region_to": "Black Sea"                               â”‚
â”‚   },                                                         â”‚
â”‚   "criterion": "P1",                                        â”‚
â”‚   "adjustment": -7,                                         â”‚
â”‚   "reason": "Not profitable for Handy"                     â”‚
â”‚ }                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ [4] Store pattern
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MONGODB: learning_patterns                                   â”‚
â”‚                                                              â”‚
â”‚ Check for similar existing pattern:                          â”‚
â”‚ - Found similar? â†’ Increase confidence                       â”‚
â”‚ - New pattern? â†’ Store with confidence=1                     â”‚
â”‚                                                              â”‚
â”‚ Vector embedding for similarity search                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ [5] Apply in future
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ NEXT SCORING REQUEST                                         â”‚
â”‚                                                              â”‚
â”‚ Similar context detected:                                    â”‚
â”‚ - Vessel: Handymax (similar to Handysize)                   â”‚
â”‚ - From: Egypt (similar to Libya)                            â”‚
â”‚ - To: Black Sea âœ“                                           â”‚
â”‚                                                              â”‚
â”‚ System applies learned adjustment:                           â”‚
â”‚ "Based on previous corrections, reducing P1 score.          â”‚
â”‚  Similar pattern: Libyaâ†’Black Sea not profitable for Handy" â”‚
â”‚                                                              â”‚
â”‚ Confidence shown to user for transparency                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 10.2 Implementation

```python
# app/learning/feedback_collector.py

class FeedbackCollector:
    """
    Collects and processes user feedback for learning.
    """
    
    async def process_correction(
        self,
        scoring_result_id: str,
        criterion: str,
        original_score: int,
        corrected_score: int,
        user_explanation: str,
        user_id: int
    ):
        """Process user's score correction."""
        
        # 1. Fetch original scoring result
        original = await self.mongo.scoring_results.find_one({
            "_id": ObjectId(scoring_result_id)
        })
        
        # 2. Extract context
        context = {
            "vessel_type": self._categorize_vessel(original["snapshot"]["vessel"]["dwt"]),
            "cargo_type": original["snapshot"]["cargo"]["type"],
            "region_from": original["snapshot"]["vessel"]["open_area"],
            "region_to": original["snapshot"]["cargo"]["load_region"],
            "season": self._get_season(original["created_at"])
        }
        
        # 3. Create pattern
        pattern = {
            "pattern_type": "score_correction",
            "context": context,
            "criterion": criterion,
            "original": {
                "score": original_score,
                "reasoning": original["scores"][criterion]["reasoning"]
            },
            "corrected": {
                "score": corrected_score,
                "user_explanation": user_explanation
            },
            "adjustment": corrected_score - original_score,
            "created_by": user_id,
            "created_at": datetime.utcnow()
        }
        
        # 4. Check for similar patterns
        similar = await self._find_similar_patterns(context, criterion)
        
        if similar:
            # Update existing pattern confidence
            await self._reinforce_pattern(similar["_id"], pattern)
        else:
            # Create new pattern
            pattern["confidence"] = 1
            pattern["applied_count"] = 0
            await self.mongo.learning_patterns.insert_one(pattern)
        
        # 5. Generate embedding for future similarity search
        await self._create_pattern_embedding(pattern)
    
    async def _find_similar_patterns(self, context: dict, criterion: str) -> Optional[dict]:
        """Find similar learned patterns using vector search."""
        query = f"{context['vessel_type']} {context['region_from']} to {context['region_to']} {context['cargo_type']}"
        
        # Vector similarity search
        results = await self.vector_store.asimilarity_search(
            query,
            k=3,
            pre_filter={
                "pattern_type": "score_correction",
                "criterion": criterion
            }
        )
        
        # Check if any result is similar enough
        for result in results:
            if self._context_matches(result["context"], context):
                return result
        
        return None
    
    async def _reinforce_pattern(self, pattern_id: ObjectId, new_correction: dict):
        """Reinforce existing pattern with new confirmation."""
        await self.mongo.learning_patterns.update_one(
            {"_id": pattern_id},
            {
                "$inc": {"confidence": 1},
                "$push": {"confirmations": new_correction},
                "$set": {"last_confirmed": datetime.utcnow()}
            }
        )
```

---

## 11. TECHNOLOGY STACK

### 11.1 Backend Stack

| Component | Technology | Version | Purpose |
|-----------|------------|---------|---------|
| Main App | Laravel | 11.x | Existing CRM, orchestration |
| AI Service | Python | 3.11+ | AI agents, scoring |
| API Framework | FastAPI | 0.104+ | Python API endpoints |
| AI Framework | LangChain | 0.1+ | Agent orchestration |
| Queue | RabbitMQ | 3.12+ | Async messaging |
| Cache | Redis | 7.x | Caching, sessions |
| Primary DB | MySQL | 8.x | Transactional data |
| AI DB | MongoDB Atlas | 7.x | Vectors, learning |

### 11.2 AI/ML Stack

| Component | Technology | Purpose |
|-----------|------------|---------|  
| Primary LLM | Claude 3.5 Sonnet | Scoring, reasoning |
| Backup LLM | GPT-4 Turbo | Fallback |
| Embeddings | OpenAI Ada-002 | Vector embeddings |
| Vector Search | MongoDB Atlas Search | RAG retrieval |
| Fuzzy Match | RapidFuzz | Text matching |
| **â˜… Workflow Engine** | **LangGraph** | **State management, conditional routing, checkpoints** |
| **â˜… Observability** | **LangSmith** | **Tracing, datasets, evaluation, monitoring** |
| **â˜… API Framework** | **LangServe** | **FastAPI integration, streaming, playground** |

### 11.3 Infrastructure

```yaml
# docker-compose.yaml (development)

version: '3.8'

services:
  
  # Existing Laravel app (DDEV)
  # ... existing config ...
  
  # New Python AI Service
  ai-service:
    build:
      context: ./vkchart-ai-service
      dockerfile: Dockerfile
    ports:
      - "8001:8000"
    environment:
      - MONGODB_URI=${MONGODB_URI}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - RABBITMQ_URL=${RABBITMQ_URL}
      - LOG_LEVEL=INFO
    volumes:
      - ./vkchart-ai-service:/app
      - ./knowledge_base:/app/knowledge_base
    depends_on:
      - rabbitmq
    restart: unless-stopped
  
  # RabbitMQ (if not already in DDEV)
  rabbitmq:
    image: rabbitmq:3.12-management
    ports:
      - "5672:5672"
      - "15672:15672"  # Management UI
    environment:
      - RABBITMQ_DEFAULT_USER=vkchart
      - RABBITMQ_DEFAULT_PASS=${RABBITMQ_PASSWORD}
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
    restart: unless-stopped

volumes:
  rabbitmq_data:
```

### 11.4 Python Dependencies

```txt
# requirements.txt

# Core
fastapi==0.104.1
uvicorn[standard]==0.24.0
pydantic==2.5.2
python-dotenv==1.0.0

# AI/LLM
langchain==0.1.0
langchain-anthropic==0.1.1
langchain-openai==0.0.5
langchain-mongodb==0.1.1
langgraph==0.2.0  # State management, workflows
langsmith==0.1.0  # Observability, tracing
langserve[all]==0.1.0  # API deployment

# Database
motor==3.3.2  # Async MongoDB
pymongo==4.6.1
redis==5.0.1

# Queue
aio-pika==9.3.1  # Async RabbitMQ

# Text Processing
rapidfuzz==3.5.2
pyyaml==6.0.1
tiktoken==0.5.2

# Utilities
httpx==0.25.2
structlog==23.2.0
tenacity==8.2.3  # Retries

# Testing
pytest==7.4.3
pytest-asyncio==0.21.1
pytest-cov==4.1.0
```

---

## 12. IMPLEMENTATION PHASES

### Phase 1: Foundation (Week 1-2)
**Goal**: Working scoring for 4 criteria + basic message generation

```
Week 1:
â”œâ”€â”€ Day 1-2: Setup
â”‚   â”œâ”€â”€ Python project structure
â”‚   â”œâ”€â”€ FastAPI endpoints
â”‚   â”œâ”€â”€ MongoDB connection
â”‚   â””â”€â”€ RabbitMQ setup
â”‚
â”œâ”€â”€ Day 3-4: Normalization
â”‚   â”œâ”€â”€ Port normalizer (rules + fuzzy)
â”‚   â”œâ”€â”€ Region normalizer
â”‚   â””â”€â”€ Basic aliases files
â”‚
â””â”€â”€ Day 5: Laravel Integration
    â”œâ”€â”€ Event dispatchers
    â”œâ”€â”€ Queue jobs
    â””â”€â”€ Basic API client

Week 2:
â”œâ”€â”€ Day 1-2: Scoring Agent (P1, P5, P6, P7)
â”‚   â”œâ”€â”€ Tools implementation
â”‚   â”œâ”€â”€ Knowledge loading
â”‚   â””â”€â”€ Basic RAG
â”‚
â”œâ”€â”€ Day 3-4: Message Agent (basic)
â”‚   â”œâ”€â”€ Template loading
â”‚   â”œâ”€â”€ Basic personalization
â”‚   â””â”€â”€ Email generation
â”‚
â””â”€â”€ Day 5: Integration Testing
    â”œâ”€â”€ End-to-end flow
    â”œâ”€â”€ Fix issues
    â””â”€â”€ Demo
```

**Deliverables**:
- [ ] Scoring for P1 (Proximity), P5 (Intake), P6 (OpenArea), P7 (Readiness)
- [ ] Basic message generation
- [ ] Laravel â†” Python integration
- [ ] Admin can test scoring via UI

### Phase 2: Full Scoring (Week 3)
**Goal**: All 7 criteria working

```
Week 3:
â”œâ”€â”€ Day 1-2: Remaining Criteria
â”‚   â”œâ”€â”€ P1A (Regional Patterns)
â”‚   â”œâ”€â”€ P2 (Regional Preferences)
â”‚   â”œâ”€â”€ P3 (Cargo Preferences)
â”‚   â””â”€â”€ P4 (Last Ports)
â”‚
â”œâ”€â”€ Day 3: Knowledge Base Enhancement
â”‚   â”œâ”€â”€ All YAML files converted
â”‚   â”œâ”€â”€ RAG indexing
â”‚   â””â”€â”€ Testing retrieval
â”‚
â”œâ”€â”€ Day 4: LLM Fallback Normalizer
â”‚   â”œâ”€â”€ Implementation
â”‚   â”œâ”€â”€ Auto-add aliases
â”‚   â””â”€â”€ Notification system
â”‚
â””â”€â”€ Day 5: Testing & Tuning
    â”œâ”€â”€ 50 test cases
    â”œâ”€â”€ Accuracy measurement
    â””â”€â”€ Prompt tuning
```

**Deliverables**:
- [ ] All P1-P7 criteria working
- [ ] LLM fallback for normalization
- [ ] Auto-alias pending review UI
- [ ] >80% accuracy on test cases

### Phase 3: Learning & Polish (Week 4)
**Goal**: Learning loop + production-ready

```
Week 4:
â”œâ”€â”€ Day 1-2: Learning System
â”‚   â”œâ”€â”€ Feedback collector
â”‚   â”œâ”€â”€ Pattern storage
â”‚   â”œâ”€â”€ Pattern application
â”‚   â””â”€â”€ UI for corrections
â”‚
â”œâ”€â”€ Day 3: Message Enhancement
â”‚   â”œâ”€â”€ All templates
â”‚   â”œâ”€â”€ Full personalization
â”‚   â”œâ”€â”€ Reminder logic
â”‚   â””â”€â”€ WhatsApp format
â”‚
â”œâ”€â”€ Day 4: Monitoring & Logging
â”‚   â”œâ”€â”€ Metrics collection
â”‚   â”œâ”€â”€ Error tracking
â”‚   â”œâ”€â”€ Performance monitoring
â”‚   â””â”€â”€ Cost tracking
â”‚
â””â”€â”€ Day 5: Production Prep
    â”œâ”€â”€ Security review
    â”œâ”€â”€ Load testing
    â”œâ”€â”€ Documentation
    â””â”€â”€ Deployment
```

**Deliverables**:
- [ ] Learning from corrections
- [ ] Full message personalization
- [ ] Monitoring dashboard
- [ ] Production deployment

---

## 13. RISKS & MITIGATIONS

### Technical Risks

| Risk | Probability | Impact | Mitigation |
|------|------------|--------|------------|
| LLM latency too high | Medium | High | Implement caching, batch processing |
| LLM costs exceed budget | Medium | Medium | Monitor costs, use smaller models where possible |
| Scoring accuracy < 80% | Medium | High | More training examples, prompt engineering |
| RabbitMQ bottleneck | Low | Medium | Horizontal scaling, priority queues |
| MongoDB performance | Low | Medium | Proper indexing, connection pooling |

### Schedule Risks

| Risk | Probability | Impact | Mitigation |
|------|------------|--------|------------|
| Integration delays | High | Medium | Start integration early, mock APIs |
| Scope creep | High | High | Strict MVP scope, backlog management |
| Knowledge base incomplete | Medium | Medium | Iterative improvement, fallback rules |
| Testing time insufficient | Medium | High | Automated tests, parallel testing |

### Operational Risks

| Risk | Probability | Impact | Mitigation |
|------|------------|--------|------------|
| User adoption low | Medium | Medium | Training, gradual rollout |
| False positives in scoring | Medium | High | Human review for high-impact decisions |
| Data quality issues | Medium | Medium | Validation, normalization |

---

## 14. LANGGRAPH & LANGSMITH INTEGRATION

### 14.1 LangGraph Workflow Architecture

**ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸Ğ¸:**
- **State Graph**: Ğ“Ñ€Ğ°Ñ„ Ñ ĞºĞ¾Ğ½ĞµÑ‡Ğ½Ñ‹Ğ¼ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸ĞµĞ¼, ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ÑÑÑ‰Ğ¸Ğ¹ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ¼ ÑĞºĞ¾Ñ€Ğ¸Ğ½Ğ³Ğ°
- **Nodes**: ĞšÑ€Ğ¸Ñ‚ĞµÑ€Ğ¸Ğ¸ P1-P7, ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ - Ğ½Ğ¾Ğ´Ğ° Ğ² Ğ³Ñ€Ğ°Ñ„Ğµ
- **Edges**: Ğ£ÑĞ»Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ¿ĞµÑ€ĞµÑ…Ğ¾Ğ´Ñ‹ Ğ¼ĞµĞ¶Ğ´Ñƒ ĞºÑ€Ğ¸Ñ‚ĞµÑ€Ğ¸ÑĞ¼Ğ¸
- **Checkpoints**: Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ Ğ´Ğ»Ñ Human-in-the-Loop

```python
# app/workflows/scoring_workflow.py

from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from typing import TypedDict, Annotated
import operator

class ScoringState(TypedDict):
    """State for scoring workflow."""
    # Input data
    vessel: dict
    cargo: dict
    company: dict
    
    # Scores (accumulated)
    scores: Annotated[dict, operator.add]
    
    # Control flow
    current_criterion: str
    is_blocked: bool
    block_reason: str
    
    # Results
    final_score: int
    reasoning_summary: str
    
def create_scoring_workflow():
    """Create LangGraph workflow for scoring."""
    
    # Initialize workflow
    workflow = StateGraph(ScoringState)
    
    # Add nodes for each criterion
    workflow.add_node("normalize", normalize_data)
    workflow.add_node("check_data", check_data_quality)
    workflow.add_node("p1_proximity", score_p1)
    workflow.add_node("p1a_patterns", score_p1a)
    workflow.add_node("p2_regional", score_p2)
    workflow.add_node("p3_cargo", score_p3)
    workflow.add_node("p4_last_ports", score_p4)
    workflow.add_node("p5_intake", score_p5)
    workflow.add_node("p6_open_area", score_p6)
    workflow.add_node("p7_readiness", score_p7)
    workflow.add_node("finalize", finalize_scoring)
    
    # Define edges
    workflow.set_entry_point("normalize")
    workflow.add_edge("normalize", "check_data")
    workflow.add_edge("check_data", "p1_proximity")
    workflow.add_edge("p1_proximity", "p1a_patterns")
    workflow.add_edge("p1a_patterns", "p2_regional")
    workflow.add_edge("p2_regional", "p3_cargo")
    workflow.add_edge("p3_cargo", "p4_last_ports")
    workflow.add_edge("p4_last_ports", "p5_intake")
    
    # Conditional routing after P5 (intake check)
    workflow.add_conditional_edges(
        "p5_intake",
        check_intake_block,
        {
            "continue": "p6_open_area",
            "block": "finalize"
        }
    )
    
    workflow.add_edge("p6_open_area", "p7_readiness")
    
    # Conditional routing after P6 (preferences check)
    workflow.add_conditional_edges(
        "p7_readiness",
        check_p6_block,
        {
            "continue": "finalize",
            "block": "finalize"
        }
    )
    
    workflow.add_edge("finalize", END)
    
    # Add checkpointer for human-in-the-loop
    memory = MemorySaver()
    app = workflow.compile(checkpointer=memory)
    
    return app

def check_intake_block(state: ScoringState) -> str:
    """Check if vessel should be blocked based on intake."""
    if state["scores"]["p5_intake"]["score"] <= 0:
        state["is_blocked"] = True
        state["block_reason"] = "Intake capacity insufficient"
        return "block"
    return "continue"

def check_p6_block(state: ScoringState) -> str:
    """Check if vessel should be blocked based on P6 score."""
    if state["scores"]["p6_open_area"]["score"] <= -40:
        state["is_blocked"] = True
        state["block_reason"] = "Owner explicitly avoids this trade"
        return "block"
    return "continue"
```

### 14.2 LangSmith Integration

**Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ğ¾Ğ½Ğ°Ğ»:**
1. **Auto-tracing**: ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ·Ğ°Ğ¿Ğ¸ÑÑŒ Ğ²ÑĞµÑ… LLM Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğ¾Ğ²
2. **Datasets**: Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ test sets Ğ´Ğ»Ñ evaluation
3. **Evaluation**: Ğ˜Ğ·Ğ¼ĞµÑ€ĞµĞ½Ğ¸Ğµ accuracy scoring
4. **Monitoring**: Real-time dashboards Ğ² production

```python
# app/config.py

import os
from langsmith import Client

# LangSmith configuration
LANGSMITH_API_KEY = os.getenv("LANGSMITH_API_KEY")
LANGSMITH_PROJECT = "vkchart-scoring"

os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_PROJECT"] = LANGSMITH_PROJECT
os.environ["LANGCHAIN_API_KEY"] = LANGSMITH_API_KEY

langsmith_client = Client()

# app/evaluation/evaluator.py

from langsmith import evaluate
from langsmith.schemas import Run, Example

class ScoringEvaluator:
    """Evaluate scoring accuracy using LangSmith."""
    
    async def create_dataset(self, name: str, examples: list):
        """Create evaluation dataset."""
        dataset = self.client.create_dataset(name)
        
        for example in examples:
            self.client.create_example(
                inputs={
                    "vessel": example["vessel"],
                    "cargo": example["cargo"]
                },
                outputs={
                    "expected_score": example["expected_score"],
                    "expected_classification": example["expected_class"]
                },
                dataset_id=dataset.id
            )
    
    async def run_evaluation(self, dataset_name: str):
        """Run evaluation on dataset."""
        
        def score_accuracy(run: Run, example: Example) -> dict:
            """Calculate scoring accuracy."""
            predicted = run.outputs["final_score"]
            expected = example.outputs["expected_score"]
            
            diff = abs(predicted - expected)
            
            return {
                "score": 1.0 - (diff / 100),  # Normalize to 0-1
                "diff": diff
            }
        
        results = evaluate(
            lambda inputs: self.scoring_agent.score(inputs),
            data=dataset_name,
            evaluators=[score_accuracy],
            experiment_prefix="scoring-eval"
        )
        
        return results
```

### 14.3 LangServe Deployment

```python
# app/main.py

from fastapi import FastAPI
from langserve import add_routes
from app.workflows.scoring_workflow import create_scoring_workflow
from app.agents.message_agent import create_message_chain

app = FastAPI(
    title="VK Chart AI Service",
    version="2.0",
    description="Vessel-Cargo Scoring & Message Generation"
)

# Create workflows
scoring_workflow = create_scoring_workflow()
message_chain = create_message_chain()

# Add LangServe routes with streaming
add_routes(
    app,
    scoring_workflow.with_types(
        input_type=ScoringInput,
        output_type=ScoringOutput
    ),
    path="/scoring",
    enable_feedback_endpoint=True,
    enable_public_trace_link_endpoint=True
)

add_routes(
    app,
    message_chain,
    path="/messages",
    enable_feedback_endpoint=True
)

# Playground UI available at /scoring/playground
```

### 14.4 Human-in-the-Loop Pattern

```python
# app/workflows/hitl.py

async def score_with_correction_loop(
    vessel: dict,
    cargo: dict,
    user_id: int
):
    """Score with ability to correct and resume."""
    
    # Create unique thread ID
    thread_id = f"scoring_{vessel['id']}_{cargo['id']}_{user_id}"
    
    config = {
        "configurable": {
            "thread_id": thread_id
        }
    }
    
    # Run workflow
    workflow = create_scoring_workflow()
    result = await workflow.ainvoke(
        {
            "vessel": vessel,
            "cargo": cargo
        },
        config=config
    )
    
    # Show result to user
    # User can correct specific criterion
    
    return result

async def correct_and_resume(
    thread_id: str,
    criterion: str,
    corrected_score: int,
    reason: str
):
    """Correct score and resume workflow."""
    
    workflow = create_scoring_workflow()
    
    # Get current state
    state = workflow.get_state(
        config={"configurable": {"thread_id": thread_id}}
    )
    
    # Update specific score
    state.values["scores"][criterion]["score"] = corrected_score
    state.values["scores"][criterion]["reasoning"] += f" [User correction: {reason}]"
    
    # Resume from checkpoint
    result = await workflow.ainvoke(
        None,  # Resume from current state
        config={
            "configurable": {"thread_id": thread_id}
        }
    )
    
    # Log correction for learning
    await log_correction(thread_id, criterion, corrected_score, reason)
    
    return result
```

### 14.5 Benefits Summary

| Feature | Before | After (with Lang* Stack) |
|---------|--------|-------------------------|
| **State Management** | Manual dict passing | LangGraph state graph |
| **Conditional Logic** | If-else in code | Conditional edges in graph |
| **Debugging** | Print statements | LangSmith trace explorer |
| **Testing** | Manual test cases | LangSmith datasets |
| **Corrections** | Rerun from scratch | Resume from checkpoint |
| **Monitoring** | Custom logging | LangSmith dashboard |
| **API Docs** | Manual Swagger | LangServe auto-docs + playground |
| **Streaming** | Custom SSE | Built-in streaming |

---

## APPENDIX A: File Conversion Guide

### Converting .txt to .yaml for RAG

Current files need conversion:
- `proximity_scoring_matrix.txt` â†’ `proximity_scoring_matrix.yaml`
- `regional_trade_patterns.txt` â†’ `regional_trade_patterns.yaml`
- etc.

**Structure**:
```yaml
# proximity_scoring_matrix.yaml

metadata:
  criterion: P1
  version: "1.0"
  description: "Proximity scoring rules"

levels:
  - level: 1
    name: "Same Port"
    score_range: [23, 25]
    description: "Vessel at loading port"
    examples:
      - vessel_location: "Odessa"
        load_port: "Odessa"
        score: 25
        
  - level: 2
    name: "Same Sub-Region"
    score_range: [20, 23]
    # ...

size_adjustments:
  - vessel_size: "Coaster"
    dwt_range: [0, 17000]
    adjustments:
      long_distance_penalty: -5
      short_distance_bonus: +2

exceptions:
  - condition: "Libya to Black Sea"
    vessel_sizes: ["Handysize", "Handymax"]
    adjustment: -7
    reason: "Not profitable for this size"
```

---

## APPENDIX B: Testing Checklist

### Scoring Tests
- [ ] P1: Same port = 25 points
- [ ] P1: Different sea = 5-10 points
- [ ] P5: Intake < 90% = BLOCK
- [ ] P6: "no grains" + grain cargo = -40
- [ ] P7: ETA before laycan = high score
- [ ] P7: ETA after laycan = low score
- [ ] Final score calculation correct
- [ ] Blocking conditions work

### Normalization Tests
- [ ] Exact match: "odessa" â†’ "UAODS"
- [ ] Fuzzy match: "odesa" â†’ "UAODS"
- [ ] LLM fallback: "cta" â†’ "ROCTA"
- [ ] Auto-add to pending

### Message Tests
- [ ] Strong match template selected for score > 85
- [ ] Personalization by nationality
- [ ] No greeting if today_contact
- [ ] Reminder references previous message

### Integration Tests
- [ ] Laravel â†’ RabbitMQ â†’ Python â†’ MongoDB â†’ Laravel
- [ ] Error handling on LLM failure
- [ ] Timeout handling
- [ ] Retry logic

---

*End of Architecture Document*
